<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">



<title>Doing model interpretation in parallel</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Doing model interpretation in parallel</h1>



<p>The <code>iml</code> package can now handle bigger datasets. Earlier problems with exploding memory have been fixed for <code>Partial</code>, <code>FeatureImp</code> and <code>Interaction</code>. Itâ€™s also possible now to compute <code>FeatureImp</code> and <code>Interaction</code> in parallel. This document describes how.</p>
<p>First we load some data, fit a random forest and create a Predictor object.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">42</span>)
<span class="kw">library</span>(<span class="st">&quot;iml&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;randomForest&quot;</span>)
<span class="kw">data</span>(<span class="st">&quot;Boston&quot;</span>, <span class="dt">package  =</span> <span class="st">&quot;MASS&quot;</span>)
rf =<span class="st"> </span><span class="kw">randomForest</span>(medv <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> Boston, <span class="dt">ntree =</span> <span class="dv">500</span>)
X =<span class="st"> </span>Boston[<span class="kw">which</span>(<span class="kw">names</span>(Boston) <span class="op">!=</span><span class="st"> &quot;medv&quot;</span>)]
predictor =<span class="st"> </span>Predictor<span class="op">$</span><span class="kw">new</span>(rf, <span class="dt">data =</span> X, <span class="dt">y =</span> Boston<span class="op">$</span>medv)</code></pre></div>
<div id="going-parallel" class="section level2">
<h2>Going parallel</h2>
<p>You need to install the <code>doParallel</code> or a similar framework to compute in parallel. Before you can use parallelization to compute for example the feature importance on multiple CPU cores, you have to setup up a cluster. Fortunately, the <code>doParallel</code> makes it easy to setup and register a cluster:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;doParallel&quot;</span>)
<span class="co">#&gt; Loading required package: iterators</span>
<span class="co">#&gt; Loading required package: parallel</span>
<span class="co"># Creates a cluster with 4 cores</span>
cl =<span class="st"> </span><span class="kw">makePSOCKcluster</span>(<span class="dv">4</span>)
<span class="co"># Registers cluster</span>
<span class="kw">registerDoParallel</span>(cl)</code></pre></div>
<p>Now we can easily compute feature importance in parallel. This means that the computation per feature is distributed among the 4 cores I specified earlier.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">imp =<span class="st"> </span>FeatureImp<span class="op">$</span><span class="kw">new</span>(predictor, <span class="dt">loss =</span> <span class="st">&quot;mae&quot;</span>, <span class="dt">parallel =</span> <span class="ot">TRUE</span>)
<span class="kw">plot</span>(imp)</code></pre></div>
<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAASAAAAEgCAMAAAAjXV6yAAAC8VBMVEUAAAACAgIDAwMEBAQFBQUGBgYHBwcICAgJCQkKCgoLCwsMDAwNDQ0ODg4PDw8QEBARERESEhITExMUFBQVFRUWFhYXFxcYGBgZGRkaGhobGxscHBwdHR0fHx8gICAhISEiIiIjIyMkJCQlJSUmJiYnJycoKCgpKSkqKiorKyssLCwtLS0vLy8xMTEyMjIzMzM0NDQ1NTU2NjY3Nzc4ODg5OTk6Ojo7Ozs8PDw9PT0+Pj4/Pz9AQEBBQUFCQkJDQ0NERERFRUVGRkZHR0dISEhJSUlKSkpLS0tMTExNTU1OTk5PT09QUFBRUVFSUlJTU1NUVFRVVVVWVlZXV1dYWFhZWVlaWlpbW1tcXFxdXV1eXl5fX19gYGBhYWFiYmJjY2NkZGRlZWVmZmZnZ2doaGhpaWlqampra2ttbW1ubm5vb29wcHBxcXFycnJzc3N0dHR1dXV2dnZ3d3d4eHh5eXl6enp7e3t8fHx9fX1+fn5/f3+AgICBgYGCgoKDg4OEhISFhYWGhoaHh4eIiIiJiYmKioqLi4uMjIyNjY2Ojo6Pj4+QkJCRkZGSkpKTk5OUlJSVlZWWlpaXl5eYmJiZmZmampqbm5ucnJydnZ2enp6fn5+goKChoaGioqKjo6OkpKSlpaWmpqanp6eoqKipqamqqqqrq6usrKytra2urq6vr6+wsLCxsbGysrKzs7O0tLS1tbW2tra3t7e4uLi5ubm6urq7u7u8vLy9vb2+vr6/v7/AwMDBwcHCwsLDw8PExMTFxcXGxsbHx8fIyMjJycnKysrLy8vMzMzNzc3Ozs7Pz8/Q0NDR0dHS0tLT09PU1NTV1dXW1tbX19fY2NjZ2dna2trb29vc3Nzd3d3e3t7f39/g4ODh4eHi4uLj4+Pk5OTl5eXm5ubn5+fo6Ojp6enq6urr6+vs7Ozt7e3u7u7v7+/w8PDx8fHy8vLz8/P09PT19fX29vb39/f4+Pj5+fn6+vr7+/v8/Pz9/f3+/v7///+JzyLAAAAACXBIWXMAAA7DAAAOwwHHb6hkAAASsklEQVR4nO2de3wURZ7A+7Lnvtg9BUH2WG+FRe+xuLKoux5CVk9cMQGMCsYEjBBMVJYQIaghIlmQx2XBBJEgYNAoiERAuIAGCI9ogAhiyBIgCfKGEPKezHv699d1VVfPTD9qenqISaanvn8k0/3rXzX5fro76aKqfhwwAsJ19z+gp8ME6cAE6cAE6cAE6cAE6dAZgtoIVlcbjXYbNWR1UkMWepbNQc+yhpLVoczqREENBIv3k4pGGzXU4aGGmq3UkNVNDbVYqCG7ixpqbVfsYILkMEEIJgjBBCF6mqCaWeSD+wlQfZKaZILML+jSZe8Ow4Lcy55N+ByyY2ZAUeKEV5vwJ5MJOjGK4+LqyA7Dgva+Yjs31iZcN/VP1TsWfmrGK+ghTmAC2WFY0J6UOh7fWI4msOQUiIIaU1NTNzsJ7lkPhcLDPSVrJPLD9XPgH6bDsCDXJ89OKeYFLe7CaWnp5hV0W6iCrre4jz1XI2gpTWuEogIz3mKPIEHxZIdhQRsynR0px9xjPJ+9xV/7az4In8wm6OTjwiPoDNlhWFDbnGcS1/J8VmrLzKTZpS/VCJ/MJqih4cpV7w5jggIiNWkCQX4wQXKYIAQThGCCEEwQgglCMEEIJgjBBDFBQcA3hY2g6uJ/KEI/vKC6ufNmnX1tTUbW14uSinu4oAzh1TxNHuoCQeO22c7GXOCnZ/FVU3q2oC24d2ejLNQFgpJ4OJsCsLQY2hOF7fro6Oh8XmLcLT2In2JBs3l/hCdEsNhDFDQD4GyaIKgULEhQW25u7ldWgnN1OpWZ9EgGNfTKjWT9GQuab/XH7bHSsDvk2yEOXqhLlwvCSBdlz7rFKm8X/Pz6qCzUBbdY+Ahq2D968F9K5aGuFbSihwvSgP2hiGCCEEwQgglCMEEIJgjBBDFBTJAPJkgOE4QIJ0EVf88Xx1GYRVBd1sfzXjwNsDt54lIr7HyDt0+pvQFB7wqv2reXo0+mETS2Gj5dDOcTLrgWrQN+xuH1+cJeT2trq/06wdJeS+PMFfl2Ne6seQRlWT3XabTYqCGbmxpq7aCG7C5qqM2i2GFY0FSAb9+EopXCx1SAU8nJFmHvlaFDh+Z6j/kfzhgDgj15N+Ag34MXlA5w7E1YswmgdbywnbYS7bWVlJTUSBOI7PvW0fhgvXw7Hwu6H2U5ePrEJvrsJYeHPrHJTg053dSQVTH1qiVEQUXCjXUmBaAiLfGaFJLuWiPPoFQkaAP6ZJpnkCjofMIV95I14Jhat2nhjQi6tvLpSV/gT2YSVFWMf4vldEDhcnAmV96AIB9mERQAqUkmiAlignwwQXKYIAQThGCCEEwQgglCMEGISBHENx2OvyFB9cuTZlbKQ+YQVJL87CoeDVD8LgZuZIziGPQSXyELmULQ90kNTSmH0QBF4Z3Vf4yi49ChQ+dbCLYjW2hs3YG/LcPdQM+1+GPnW2i026khu4castioIYebGuqwyrebDQkq/BDgZB0aoIgE+Y1RDKlH8aGgztnNGOtRfHsH+ooGKCJBfiPM3BcvXmxtIlgvH6XxbTX+thkLSm3yx8Y30Wi1UUN2DzXU1kENOVzUULsiq9GQoHXrAU6fQF1CCkEY6a4N4hn0kuBnYLUsZIpnUPWUJsv0fZ0gqGFbVt55ecgUgmDb5ETht5hcEBujGCxSk0wQE8QE+WCC5DBBCCYIwQQhmCAEE4QwmyD0dzQTFFiQsldRalJfUPHjw144pQiZSRD/6cSphWnwXQxZVNGooC9RZ8eQS/KQmQQdeb7ekp6GXljFRRUBLAUFBd9YCI4N82hkL0Bfh+LuoGKLDCdvoWF1UkNODzVkc1BDLnqWXZEV0pzVFZsAyrAgcVFFo7Oe/xkL+lgxvzj4mcihzV8OLSukWc8L9gOcxoLERRXJbumi1L3FsrAg+TxbU91iK4sAyrEgcVFFo4IuoU7rxYqQmQQdm9xgm40FiYsqGhXU0LB3g3I5DVMJ4jdOmrpzERIkLqpoXJAGZhJEQWqSCWKCmCAfTJAcJgjBBCF+OEFNW3OgyskEiagFnbptAAexd55hgjBqQY9NcEfBtVFjmSCMWlCvgxAFsPdmxY/vW7tevRVZggbsRYJ2/VpLkHf1RGFLNUxRajKwoFNP9e6belEdCh9BySOaoqDyd9JK9VC6fNHMzHpUgQUNTvTVY/kuRpr7bEgQLjmQog6Fj6DmET/ibubGWbyCxp6FzXPQNYMGJ/rqsQjvqmTus5CTkZFRbCe4suOoPDlGnMZrV+Hm1fsITjc1FCjL1RlZFrUg4MvXFp3ybZZmAjjGOpGSJN6vHosgSJr7DNcTEhI2uAieF++hMvRuLKi/S4UH1PsIbg815OFDyeKDz7KqBNWO/l7+aCnNEb7ENyIlM8CvHosgyDv32cAtNgwJmqAOhc0tZu+zRiHoVYCOsW5RiV89FnQFkbnPRgQduZfjHqtVh8JGEGwdvOSLAwJeQbGVnvfmowosSJCvHgt+BuG5z4YENTScOqMVCh9BUQSvoLmZCZnXgc9KRYJ89VjQljj32aAgbcJHkJLSXHpMhtSk2QU1i0j/Y8YEKQWRiQL3Bakl8gRVCxxddXcVE4RRCxLZGc0EYWiCjvdigjBqQccR+//y70wQRi1IfEb33ckEYdSC2jG8pgMRjeF3kSRoFP7aJOsylHeOhSio7uBlEwhasoRbgkjp7f+zfxcjrQ9Iht9VZgKU5RgZgndtCscNKAx/QQ88wD2AGC57pxfeu8j6gGT4HREkDcELQlAOfrRpvqdiwkUQwFCNuwcJEtcHJMPviCBpCF4QHWa3YEEb6V1f4dJhRjg2WilIXN2NDL8jgqQheK3z58/fbSO4lk7W4LdY0HYbDRdPDTlc1JA7tCwPPcsp325XC/p2WB+Bm8ZoCyLD7ypfA9iWY2QI3kbkZyD10g6jW2z48A/7rln1rzXagsjwu5qnW2xpOYaG4K3+3a2jDof/Qxrg53tg0lbIj9MQVFUsDb/jl8bPKimIzCF4v9gFb78CNX2UTyVdpCbNLujhkbV7B9k+6McEYdSCqn+/0HH/z7gsJgijFgTgAcu2vYFexiJcEBtA5Y9aEBtAJUMtiA2gkqEWRBlAxQRJUAZQMUESygFUTJBCkHIAVWcJOvr+5/WmEKQcQCVHHIEH25NeWJcJcOSl55dJHQI6ghYJL/N/OBf2grIvBL5KyAi805Ovt7+cCU0TvnfnLQtKUCXuDpoe9oK4coATAf5bnozAe389QHEm7FwgaJkKwS8TaPy/a7sb5TKBSFBFgLEwZARezpcAhzPh48Rp06alCy8lHUVFRcfbCfbtuWpewYImONtpOHhqqIOe5fRQQ1Y7NeSiZ9kUWa0GBZEReGs2AOzMhP9bAeC8IsWki1LzFqv/bySoxBS3WCBBZARe1ZSWjrRMuDrxknt1TlCCGs5mRD9VEv6/xfQEkRF4sGnSXz9fDFCWkjBPuggj4+8gbmRcXDSHx3zTLQGcLOL5Dz5T7JSaNLWgMT4CCbLlpLy8xKbYKTVpakE3gtQkE8QEMUE+mCA5TBCCCUIwQYieKUhrRi8TdKOCSmZnVkSKoOyYGaRnMfhSxkvRy/yWCBEkXEGkZ1EqZew8ceJEPZkm1Gw9XapiT28k6J5WRzMNG08NtdmpIbuHGmq3UkMONzVk6ZBvS/PgjQoiPYtGSxkbOUvPwHApY4QgiPQsSqWMda+g3VyEXUGkZzH4UsZLkKCiSHkGjfGQnkUDpYx3TM8oj5TfYnxWKulZZKWMjSA1yQQxQUyQDyZIDhOEYIIQTBCCCUIwQYgwF7TrHfytZpZ8d1mO34bUJBNkQNCl7EfH7/BtmljQwrnxr9VjQWSUIq5qLAiqTroUQFAMeonf7N00saDY4678N5Ag0pcoVjUuy7mYVA30EWZzcTfQKO94LUvYjzCjCnodrfTmEgSRvkSxqnHZnOS1KBy4R/FuncZ7MsH2KO5CY1njmwRBpC9RrGpcFpOfgCZOe1pbW+3XCZb2WomjWFCiFLne5D1IhdVDDbXYqCGbmxpq7aCG7C5qqM2i2BGsIHQFPeERBJG+RLGqcdkCeLNQOka6a/2fQXmCn7t8NYvN/AyqdK9ajJ5BpC9RrGosPKTPPS3Vi5aalP2aP7py42XflnkFlRe+ljC3GQmSRiniqsbo13ze8kCC5JhXUDBITTJBTBAT5IMJksMEIZggBBOEYIIQTBDCtIJ8awZKTTJB3vIjgQSde+mOwbMvK84WEYL8yo+QRRU1BY1HHR0vK84WGYJ85UfIoooAbbm5uV9ZCc7V6enp03FP0K+scmwuKw0XTw3ZQ8tyUkNuDz3LId8OoZSxX/kRsqgiwLXY2Nh1boJn4sCBA3+DBd3qdMvw8G4aPFBDnZ9FD3k88m1pUpwRQb7yI2RRRYJ0UYq3GK54/Zjieo2MW8xXfoQsqqgp6OB/ctyw44qzRYwg0q1IFlXUFNRw9fCRa8rTR4wgqfyIuKiitiAtIkIQFalJJogJYoJ8MEFymCAEE4RgghBMEIIJQkSYoJPap48cQQeSk5NjzpBiJCpBy/tzv1qhdfrIESSw/VWeFCNRCqrAfUG7NE4fSYIuJNZLxUgAGlNTUzc7CW68nhs316mBR2unGAFqyBUgi6dnuTsjS6oBaliQO20XSKUklLWexTGK2RqVlB2hVW3uYbWeg6Iwm/cThJEuSksVFlSmcQFHzi1WPbEFqILgozu5uz7WOn3kCMoZn5KScogUI1EJamhQ9SWKRI4gLaQm2R+KTBAT5IMJksMEIZggBBOEYIIQTBDCLILQH89M0A0KqvusinJ6cwvC03jr0lZOTqmVpvZqlTK+Nkl4lZ+jfXpTCxKn8dbFfM2v+Ls0tVerlPG71P5EkwsSp/HWPc9Dxd+kMXhSKeP66OjofF4kBQtayhsFDGegpB86yx68IHEaL3oGHfmbNAZPKmVsKSgo+MYikoEFrbVo0eHS3I1w8tSQ1UnP8lBDNgc15KJn2RVZBgZxitN4iSAyBk+rlHE58nNHreYFbOpbTJzGSwSRMXiapYzL4oY8c1T79KYWJE7jJYLIGLyILGUcMlKTTBATxAT5YILkMEEIJgjR8wRJfPtOKFkH3wsla98HoWR9+YnhlM4U9FGAIpJ08h8OJet/x4WS9Uai4RQmSAcmSIfOFNR+Sf8YNa2XQ8lquRpKVlO94ZQwLOjQtTBBOjBBOnSmIFey8VLsUJIcn3VF/zA5/PqJ8fPb9I9TcXiq0YxOFFQ8M8a4oItxl+xrXjWaVflcg23BasMng/qkZKMpnSiosnyscUHfCH99nzf8y/d8JbjfX2v4ZM6ZJd0pCOCJEG4x4Z+9eKXxpF1jU6yGk1ZsPxt+gviylPfdIZyrMW+p0ZR9i/jwE8S/Pfui8ROVlALUGf5Z3xofPz42vtlYUncLOpSGVvkwmrX/xQ7P2sX6x6kIvytobYxAvNEsfvXEiW+1GD5ZtwsyI0yQDkyQDkyQDkyQDkyQDkyQDkyQDl0uaIxYciPbWFb6f/0w/xp9ul7QyHLEBVXggSUBsoISFLCFUOl6QXGUgPzHs9fJgvqChASTCWqeevsvHj8NUP3Iv/R68BgMRaWAuOPCNtcMUZ/3Ge09AIEE/bj40X4jL0y7q28eVPQ5cF/vkf8AqH+mX//4esAJqAWpNYj6+snfDNwIcPWpPre9bJe1ZYyuFxRdIXAC+BEPlh4c378J7hlRsnv4MHwF+QQNXn3GewACC/pzc+N//HSLZ0lUe8VNf/y+I6NPq+cP9+4pvXeoByfgK0hqLerBWtecH1vdQx79at2tr8vaMkY3PaTvg/IfNQK4Bmz1LKwF+LCPQtBi8B6As7CgTwBmCD/7Za6mgtsB4L4jb0/UOeEN/Z/24gTUgre1qOUA57iabT8XpLybKGvLGN12i63logS4HHDsy53UVynoC78DEFhQKcDro4V7EwlCtYmeTH1nEAre8S5OwFeQ1FrUboAGruate+UnM063CSq6RfxuuX9Q+pbVfoKOIkEHfAdgVIJQLfcxL+T9FgUH5eEE1IK3NbRDEDTvT7KThUC3CTrJVaLFhKu2/cwGsEoStB/gPSJIOgAfrRK0CaCj77KSKOHPhfPC1SIJ8rZGBH36yzaAjx6WtWWM7vstNm7I7n2jBjv3coW1qwbcdAyGpzTxtz52vORuIkg6AB+sEnT7lq8f793i+f2fyg788R6PmCC04G2NCHIMij382b9Nk7VljO4TZEkZ8MvYOuCz+vWOqxkzGlb3Hgc77uw1suq+NvHnJQdgZIJ+UlfBbR/Sa4RwQVwd36/fM/XiBYNa8LaGBf2kDs7F3tx/mlXWljHC812sgnN11amYIB2YIB3CU1AXwgTpwATpwATpwATpwATpwATpwATp8P+IA+00geomYwAAAABJRU5ErkJggg==" /><!-- --></p>
<p>That wasnâ€™t very impressive, letâ€™s actually see how much speed up we get by parallelization.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system.time</span>(FeatureImp<span class="op">$</span><span class="kw">new</span>(predictor, <span class="dt">loss =</span> <span class="st">&quot;mae&quot;</span>, <span class="dt">parallel =</span> <span class="ot">FALSE</span>))
<span class="co">#&gt;    user  system elapsed </span>
<span class="co">#&gt;   1.188   0.016   1.213</span>
<span class="kw">system.time</span>(FeatureImp<span class="op">$</span><span class="kw">new</span>(predictor, <span class="dt">loss =</span> <span class="st">&quot;mae&quot;</span>, <span class="dt">parallel =</span> <span class="ot">TRUE</span>))
<span class="co">#&gt;    user  system elapsed </span>
<span class="co">#&gt;   0.136   0.024   0.984</span></code></pre></div>
<p>A little bit of improvement, but not too impressive. Parallelization is more useful in the case where the model uses a lot of features or where the feature importance computation is repeated more often to get more stable results.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system.time</span>(FeatureImp<span class="op">$</span><span class="kw">new</span>(predictor, <span class="dt">loss =</span> <span class="st">&quot;mae&quot;</span>, <span class="dt">parallel =</span> <span class="ot">FALSE</span>, <span class="dt">n.repetitions =</span> <span class="dv">200</span>))
<span class="co">#&gt;    user  system elapsed </span>
<span class="co">#&gt;  59.524   0.024  59.707</span>
<span class="kw">system.time</span>(FeatureImp<span class="op">$</span><span class="kw">new</span>(predictor, <span class="dt">loss =</span> <span class="st">&quot;mae&quot;</span>, <span class="dt">parallel =</span> <span class="ot">TRUE</span>, <span class="dt">n.repetitions =</span> <span class="dv">200</span>))
<span class="co">#&gt;    user  system elapsed </span>
<span class="co">#&gt;   0.116   0.024  26.185</span></code></pre></div>
<p>Here the parallel computation is twice as fast as the sequential computation of the feature importance.</p>
<p>The parallization also speeds up the computation of the interaction statistics:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system.time</span>(Interaction<span class="op">$</span><span class="kw">new</span>(predictor, <span class="dt">parallel =</span> <span class="ot">FALSE</span>))
<span class="co">#&gt;    user  system elapsed </span>
<span class="co">#&gt;  13.480   0.000  13.487</span>
<span class="kw">system.time</span>(Interaction<span class="op">$</span><span class="kw">new</span>(predictor, <span class="dt">parallel =</span> <span class="ot">TRUE</span>))
<span class="co">#&gt;    user  system elapsed </span>
<span class="co">#&gt;   0.104   0.036   6.531</span></code></pre></div>
<p>Remember to stop the cluster in the end again.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">stopCluster</span>(cl)</code></pre></div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
