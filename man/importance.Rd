% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/importance.R
\name{importance}
\alias{importance}
\title{Feature importance}
\usage{
importance(object, X, y, class = NULL, loss, method = "shuffle", ...)
}
\arguments{
\item{object}{The object is the machine learning model. Different types are allowed. 
Recommended are mlr WrappedModel and caret train objects. The \code{object} can also be 
a function that predicts the outcome given features or anything with an S3 predict function,
like an object from class \code{lm}.}

\item{X}{data.frame with the data for the prediction model}

\item{class}{In case of classification, class specifies the class for which to predict the probability. 
By default the multiclass classification is done.}

\item{loss}{The loss function to use: l(actual, predicted) -> R}
}
\description{
imp() computes the feature importance for a machine learning model. 
The importance of a feature is the loss in model performance when the feature is shuffled.
}
\details{
#' To learn more about feature importance, read the Interpretable Machine Learning book: https://christophm.github.io/interpretable-ml-book/permutation-feature-importance.html
}
